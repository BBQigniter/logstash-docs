[[plugins-outputs-csv]]
=== csv

Version: 3.0.2
Released on: 2016-07-14
https://github.com/logstash-plugins/logstash-output-csv/blob/master/CHANGELOG.md#302[Changelog]
Compatible: 5.1.1.1, 5.0.0, 2.4.1, 2.4.0, 2.3.4



CSV output.

Write events to disk in CSV or other delimited format
Based on the file output, many config values are shared
Uses the Ruby csv library internally

&nbsp;

==== Synopsis

This plugin supports the following configuration options:

Required configuration options:

[source,json]
--------------------------
csv {
    fields => ...
    path => ...
}
--------------------------



Available configuration options:

[cols="<,<,<,<m",options="header",]
|=======================================================================
|Setting |Input type|Required|Default value
| <<plugins-outputs-csv-codec>> |<<codec,codec>>|No|`"plain"`
| <<plugins-outputs-csv-create_if_deleted>> |<<boolean,boolean>>|No|`true`
| <<plugins-outputs-csv-csv_options>> |<<hash,hash>>|No|`{}`
| <<plugins-outputs-csv-dir_mode>> |<<number,number>>|No|`-1`
| <<plugins-outputs-csv-enable_metric>> |<<boolean,boolean>>|No|`true`
| <<plugins-outputs-csv-fields>> |<<array,array>>|Yes|
| <<plugins-outputs-csv-file_mode>> |<<number,number>>|No|`-1`
| <<plugins-outputs-csv-filename_failure>> |<<string,string>>|No|`"_filepath_failures"`
| <<plugins-outputs-csv-flush_interval>> |<<number,number>>|No|`2`
| <<plugins-outputs-csv-gzip>> |<<boolean,boolean>>|No|`false`
| <<plugins-outputs-csv-id>> |<<string,string>>|No|
| <<plugins-outputs-csv-path>> |<<string,string>>|Yes|
| <<plugins-outputs-csv-spreadsheet_safe>> |<<boolean,boolean>>|No|`true`
| <<plugins-outputs-csv-workers>> |<<,>>|No|`1`
|=======================================================================


==== Details

&nbsp;

[[plugins-outputs-csv-codec]]
===== `codec` 

  * Value type is <<codec,codec>>
  * Default value is `"plain"`

The codec used for output data. Output codecs are a convenient method for encoding your data before it leaves the output, without needing a separate filter in your Logstash pipeline.

[[plugins-outputs-csv-create_if_deleted]]
===== `create_if_deleted` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

If the configured file is deleted, but an event is handled by the plugin, 
the plugin will recreate the file. Default => true

[[plugins-outputs-csv-csv_options]]
===== `csv_options` 

  * Value type is <<hash,hash>>
  * Default value is `{}`

Options for CSV output. This is passed directly to the Ruby stdlib to_csv function.
Full documentation is available on the http://ruby-doc.org/stdlib-2.0.0/libdoc/csv/rdoc/index.html[Ruby CSV documentation page].
A typical use case would be to use alternative column or row seperators eg: `csv_options => {"col_sep" => "\t" "row_sep" => "\r\n"}` gives tab seperated data with windows line endings

[[plugins-outputs-csv-dir_mode]]
===== `dir_mode` 

  * Value type is <<number,number>>
  * Default value is `-1`

Dir access mode to use. Note that due to the bug in jruby system umask
is ignored on linux: https://github.com/jruby/jruby/issues/3426
Setting it to -1 uses default OS value.
Example: `"dir_mode" => 0750`

[[plugins-outputs-csv-enable_metric]]
===== `enable_metric` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Disable or enable metric logging for this specific plugin instance
by default we record all the metrics we can, but you can disable metrics collection
for a specific plugin.

[[plugins-outputs-csv-fields]]
===== `fields` 

  * This is a required setting.
  * Value type is <<array,array>>
  * There is no default value for this setting.

The field names from the event that should be written to the CSV file.
Fields are written to the CSV in the same order as the array.
If a field does not exist on the event, an empty string will be written.
Supports field reference syntax eg: `fields => ["field1", "[nested][field]"]`.

[[plugins-outputs-csv-file_mode]]
===== `file_mode` 

  * Value type is <<number,number>>
  * Default value is `-1`

File access mode to use. Note that due to the bug in jruby system umask
is ignored on linux: https://github.com/jruby/jruby/issues/3426
Setting it to -1 uses default OS value.
Example: `"file_mode" => 0640`

[[plugins-outputs-csv-filename_failure]]
===== `filename_failure` 

  * Value type is <<string,string>>
  * Default value is `"_filepath_failures"`

If the generated path is invalid, the events will be saved
into this file and inside the defined path.

[[plugins-outputs-csv-flush_interval]]
===== `flush_interval` 

  * Value type is <<number,number>>
  * Default value is `2`

Flush interval (in seconds) for flushing writes to log files.
0 will flush on every message.

[[plugins-outputs-csv-gzip]]
===== `gzip` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Gzip the output stream before writing to disk.

[[plugins-outputs-csv-id]]
===== `id` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Add a unique `ID` to the plugin instance, this `ID` is used for tracking
information for a specific configuration of the plugin.

```
output {
 stdout {
   id => "ABC"
 }
}
```

If you don't explicitely set this variable Logstash will generate a unique name.

[[plugins-outputs-csv-path]]
===== `path` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.

The path to the file to write. Event fields can be used here,
like `/var/log/logstash/%{host}/%{application}`
One may also utilize the path option for date-based log
rotation via the joda time format. This will use the event
timestamp.
E.g.: `path => "./test-%{+YYYY-MM-dd}.txt"` to create
`./test-2013-05-29.txt`

If you use an absolute path you cannot start with a dynamic string.
E.g: `/%{myfield}/`, `/test-%{myfield}/` are not valid paths

[[plugins-outputs-csv-spreadsheet_safe]]
===== `spreadsheet_safe` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Option to not escape/munge string values. Please note turning off this option
may not make the values safe in your spreadsheet application

[[plugins-outputs-csv-workers]]
===== `workers` 

  * Value type is <<string,string>>
  * Default value is `1`

TODO remove this in Logstash 6.0
when we no longer support the :legacy type
This is hacky, but it can only be herne


