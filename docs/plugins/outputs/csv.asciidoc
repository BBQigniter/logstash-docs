[[plugins-outputs-csv]]
=== csv

* Version: 3.0.3
* Released on: February 20, 2017
* https://github.com/logstash-plugins/logstash-output-csv/blob/master/CHANGELOG.md#303[Changelog]



==== Getting Help

For questions about the plugin, open a topic in the http://discuss.elastic.co[Discuss] forums. For bugs or feature requests, open an issue in https://github.com/elastic/logstash[Github].
For the list of Elastic supported plugins, please consult the https://www.elastic.co/support/matrix#show_logstash_plugins[Elastic Support Matrix].

==== Description

CSV output.

Write events to disk in CSV or other delimited format
Based on the file output, many config values are shared
Uses the Ruby csv library internally

&nbsp;

==== Synopsis

This plugin supports the following configuration options:

Required configuration options:

[source,json]
--------------------------
csv {
    fields => ...
    path => ...
}
--------------------------



Available configuration options:

[cols="<,<,<",options="header",]
|=======================================================================
|Setting |Input type|Required
| <<plugins-outputs-csv-codec>> |<<codec,codec>>|No
| <<plugins-outputs-csv-create_if_deleted>> |<<boolean,boolean>>|No
| <<plugins-outputs-csv-csv_options>> |<<hash,hash>>|No
| <<plugins-outputs-csv-dir_mode>> |<<number,number>>|No
| <<plugins-outputs-csv-enable_metric>> |<<boolean,boolean>>|No
| <<plugins-outputs-csv-fields>> |<<array,array>>|Yes
| <<plugins-outputs-csv-file_mode>> |<<number,number>>|No
| <<plugins-outputs-csv-filename_failure>> |<<string,string>>|No
| <<plugins-outputs-csv-flush_interval>> |<<number,number>>|No
| <<plugins-outputs-csv-gzip>> |<<boolean,boolean>>|No
| <<plugins-outputs-csv-id>> |<<string,string>>|No
| <<plugins-outputs-csv-path>> |<<string,string>>|Yes
| <<plugins-outputs-csv-spreadsheet_safe>> |<<boolean,boolean>>|No
| <<plugins-outputs-csv-workers>> |<<,>>|No
|=======================================================================


==== Details

&nbsp;

[[plugins-outputs-csv-codec]]
===== `codec` 

  * Value type is <<codec,codec>>
  * Default value is `"plain"`

The codec used for output data. Output codecs are a convenient method for encoding your data before it leaves the output, without needing a separate filter in your Logstash pipeline.

[[plugins-outputs-csv-create_if_deleted]]
===== `create_if_deleted` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

If the configured file is deleted, but an event is handled by the plugin, 
the plugin will recreate the file. Default => true

[[plugins-outputs-csv-csv_options]]
===== `csv_options` 

  * Value type is <<hash,hash>>
  * Default value is `{}`

Options for CSV output. This is passed directly to the Ruby stdlib to_csv function.
Full documentation is available on the http://ruby-doc.org/stdlib-2.0.0/libdoc/csv/rdoc/index.html[Ruby CSV documentation page].
A typical use case would be to use alternative column or row seperators eg: `csv_options => {"col_sep" => "\t" "row_sep" => "\r\n"}` gives tab seperated data with windows line endings

[[plugins-outputs-csv-dir_mode]]
===== `dir_mode` 

  * Value type is <<number,number>>
  * Default value is `-1`

Dir access mode to use. Note that due to the bug in jruby system umask
is ignored on linux: https://github.com/jruby/jruby/issues/3426
Setting it to -1 uses default OS value.
Example: `"dir_mode" => 0750`

[[plugins-outputs-csv-enable_metric]]
===== `enable_metric` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Disable or enable metric logging for this specific plugin instance
by default we record all the metrics we can, but you can disable metrics collection
for a specific plugin.

[[plugins-outputs-csv-fields]]
===== `fields` 

  * This is a required setting.
  * Value type is <<array,array>>
  * There is no default value for this setting.

The field names from the event that should be written to the CSV file.
Fields are written to the CSV in the same order as the array.
If a field does not exist on the event, an empty string will be written.
Supports field reference syntax eg: `fields => ["field1", "[nested][field]"]`.

[[plugins-outputs-csv-file_mode]]
===== `file_mode` 

  * Value type is <<number,number>>
  * Default value is `-1`

File access mode to use. Note that due to the bug in jruby system umask
is ignored on linux: https://github.com/jruby/jruby/issues/3426
Setting it to -1 uses default OS value.
Example: `"file_mode" => 0640`

[[plugins-outputs-csv-filename_failure]]
===== `filename_failure` 

  * Value type is <<string,string>>
  * Default value is `"_filepath_failures"`

If the generated path is invalid, the events will be saved
into this file and inside the defined path.

[[plugins-outputs-csv-flush_interval]]
===== `flush_interval` 

  * Value type is <<number,number>>
  * Default value is `2`

Flush interval (in seconds) for flushing writes to log files.
0 will flush on every message.

[[plugins-outputs-csv-gzip]]
===== `gzip` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Gzip the output stream before writing to disk.

[[plugins-outputs-csv-id]]
===== `id` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Add a unique `ID` to the plugin configuration. If no ID is specified, Logstash will generate one. 
It is strongly recommended to set this ID in your configuration. This is particularly useful 
when you have two or more plugins of the same type, for example, if you have 2 grok filters. 
Adding a named ID in this case will help in monitoring Logstash when using the monitoring APIs.

[source,ruby]
---------------------------------------------------------------------------------------------------
output {
 stdout {
   id => "my_plugin_id"
 }
}
---------------------------------------------------------------------------------------------------


[[plugins-outputs-csv-path]]
===== `path` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.

This output writes events to files on disk. You can use fields
from the event as parts of the filename and/or path.

By default, this output writes one event per line in **json** format.
You can customise the line format using the `line` codec like
[source,ruby]
output {
 file {
   path => ...
   codec => line { format => "custom format: %{message}"}
 }
}
The path to the file to write. Event fields can be used here,
like `/var/log/logstash/%{host}/%{application}`
One may also utilize the path option for date-based log
rotation via the joda time format. This will use the event
timestamp.
E.g.: `path => "./test-%{+YYYY-MM-dd}.txt"` to create
`./test-2013-05-29.txt`

If you use an absolute path you cannot start with a dynamic string.
E.g: `/%{myfield}/`, `/test-%{myfield}/` are not valid paths

[[plugins-outputs-csv-spreadsheet_safe]]
===== `spreadsheet_safe` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Option to not escape/munge string values. Please note turning off this option
may not make the values safe in your spreadsheet application

[[plugins-outputs-csv-workers]]
===== `workers` 

  * Value type is <<string,string>>
  * Default value is `1`

when we no longer support the :legacy type
This is hacky, but it can only be herne


