[[plugins-outputs-file]]
=== file



This output will write events to files on disk. You can use fields
from the event as parts of the filename and/or path.

&nbsp;

==== Synopsis

This plugin supports the following configuration options:


Required configuration options:

[source,json]
--------------------------
file {
    path => ...
}
--------------------------



Available configuration options:

[cols="<,<,<,<m",options="header",]
|=======================================================================
|Setting |Input type|Required|Default value
| <<plugins-outputs-file-codec>> |<<codec,codec>>|No|`"plain"`
| <<plugins-outputs-file-filename_failure>> |<<string,string>>|No|`"_filepath_failures"`
| <<plugins-outputs-file-flush_interval>> |<<number,number>>|No|`2`
| <<plugins-outputs-file-gzip>> |<<boolean,boolean>>|No|`false`
| <<plugins-outputs-file-message_format>> |<<string,string>>|No|
| <<plugins-outputs-file-path>> |<<string,string>>|Yes|
| <<plugins-outputs-file-workers>> |<<number,number>>|No|`1`
|=======================================================================



==== Details

&nbsp;

[[plugins-outputs-file-codec]]
===== `codec` 

  * Value type is <<codec,codec>>
  * Default value is `"plain"`

The codec used for output data. Output codecs are a convenient method for encoding your data before it leaves the output, without needing a separate filter in your Logstash pipeline.

[[plugins-outputs-file-filename_failure]]
===== `filename_failure` 

  * Value type is <<string,string>>
  * Default value is `"_filepath_failures"`

If the generated path is invalid, the events will be saved
into this file and inside the defined path.

[[plugins-outputs-file-flush_interval]]
===== `flush_interval` 

  * Value type is <<number,number>>
  * Default value is `2`

Flush interval (in seconds) for flushing writes to log files.
0 will flush on every message.

[[plugins-outputs-file-gzip]]
===== `gzip` 

  * Value type is <<boolean,boolean>>
  * Default value is `false`

Gzip the output stream before writing to disk.

[[plugins-outputs-file-message_format]]
===== `message_format` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

The format to use when writing events to the file. This value
supports any string and can include `%{name}` and other dynamic
strings.

If this setting is omitted, the full json representation of the
event will be written as a single line.

[[plugins-outputs-file-path]]
===== `path` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.

The path to the file to write. Event fields can be used here,
like `/var/log/logstash/%{host}/%{application}`
One may also utilize the path option for date-based log
rotation via the joda time format. This will use the event
timestamp.
E.g.: `path => "./test-%{+YYYY-MM-dd}.txt"` to create
`./test-2013-05-29.txt`

If you use an absolute path you cannot start with a dynamic string.
E.g: `/%{myfield}/`, `/test-%{myfield}/` are not valid paths

[[plugins-outputs-file-workers]]
===== `workers` 

  * Value type is <<number,number>>
  * Default value is `1`

The number of workers to use for this output.
Note that this setting may not be useful for all outputs.


