[[plugins-codecs-protobuf]]
=== protobuf

* Version: 1.0.0
* Released on: 2016-12-04
* https://github.com/logstash-plugins/logstash-codec-protobuf/blob/master/CHANGELOG.md#100[Changelog]
* Compatible: 5.1.1.1, 5.0.0, 2.4.1, 2.4.0, 2.3.4


NOTE: This plugin does not ship with Logstash by default, but it is easy to install by running `bin/logstash-plugin install logstash-codec-protobuf`.


This codec converts protobuf encoded messages into logstash events and vice versa. 

Requires the protobuf definitions as ruby files. You can create those using the [ruby-protoc compiler](https://github.com/codekitchen/ruby-protocol-buffers).

The following shows a usage example for decoding events from a kafka stream:
[source,ruby]
kafka 
{
 zk_connect => "127.0.0.1"
 topic_id => "your_topic_goes_here"
 codec => protobuf 
 {
   class_name => "Animal::Unicorn"
   include_path => ['/path/to/protobuf/definitions/UnicornProtobuf.pb.rb']
 }
}


&nbsp;

==== Synopsis

This plugin supports the following configuration options:

Required configuration options:

[source,json]
--------------------------
protobuf {
      class_name => ...
      include_path => ...
  }
--------------------------



Available configuration options:

[cols="<,<,<,<m",options="header",]
|=======================================================================
|Setting |Input type|Required|Default value
| <<plugins-codecs-protobuf-class_name>> |<<string,string>>|Yes|
| <<plugins-codecs-protobuf-enable_metric>> |<<boolean,boolean>>|No|`true`
| <<plugins-codecs-protobuf-id>> |<<string,string>>|No|
| <<plugins-codecs-protobuf-include_path>> |<<array,array>>|Yes|
|=======================================================================


==== Details

&nbsp;

[[plugins-codecs-protobuf-class_name]]
===== `class_name` 

  * This is a required setting.
  * Value type is <<string,string>>
  * There is no default value for this setting.

Name of the class to decode.
If your protobuf definition contains modules, prepend them to the class name with double colons like so:
[source,ruby]
class_name => "Foods::Dairy::Cheese"

This corresponds to a protobuf definition starting as follows:
[source,ruby]
module Foods
   module Dairy
       class Cheese
           # here are your field definitions.

If your class references other definitions: you only have to add the main class here.

[[plugins-codecs-protobuf-enable_metric]]
===== `enable_metric` 

  * Value type is <<boolean,boolean>>
  * Default value is `true`

Disable or enable metric logging for this specific plugin instance
by default we record all the metrics we can, but you can disable metrics collection
for a specific plugin.

[[plugins-codecs-protobuf-id]]
===== `id` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Add a unique `ID` to the plugin instance, this `ID` is used for tracking
information for a specific configuration of the plugin.

```
output {
 stdout {
   id => "ABC"
 }
}
```

If you don't explicitely set this variable Logstash will generate a unique name.

[[plugins-codecs-protobuf-include_path]]
===== `include_path` 

  * This is a required setting.
  * Value type is <<array,array>>
  * There is no default value for this setting.

List of absolute pathes to files with protobuf definitions. 
When using more than one file, make sure to arrange the files in reverse order of dependency so that each class is loaded before it is 
refered to by another.

Example: a class _Cheese_ referencing another protobuf class _Milk_
[source,ruby]
module Foods
  module Dairy
        class Cheese
           set_fully_qualified_name "Foods.Dairy.Cheese"
           optional ::Foods::Cheese::Milk, :milk, 1
           optional :int64, :unique_id, 2
           # here be more field definitions

would be configured as
[source,ruby]
include_path => ['/path/to/protobuf/definitions/Milk.pb.rb','/path/to/protobuf/definitions/Cheese.pb.rb']

When using the codec in an output plugin: 
* make sure to include all the desired fields in the protobuf definition, including timestamp. 
  Remove fields that are not part of the protobuf definition from the event by using the mutate filter.
* the @ symbol is currently not supported in field names when loading the protobuf definitions for encoding. Make sure to call the timestamp field "timestamp" 
  instead of "@timestamp" in the protobuf file. Logstash event fields will be stripped of the leading @ before conversion.
 


